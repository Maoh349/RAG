# RAG

![302837092-54a2d76c-b07e-49e7-b4ce-fc45667360a1](https://github.com/user-attachments/assets/645ceaa4-0995-47a4-938a-a148a5e89e2f)

# RAGの仕組み
チャンク化：
マニュアルなどの文章をページごとなどに分けて、チャンク化にします。

### ベクトル化：
チャンク化した文章をembedding modelを使ってベクトルに変換します。
OpenAIのtext-embedding-ada-002がよく使われます。
テキストの長さにかかわらず文章の意味を1536次元のベクトルに変換します。

### クエリの入力：
ユーザーの質問や指示を入力します。

### 情報検索：
ベクトル化されたクエリとドキュメントを用いて、類似度計算を行い、関連するドキュメントを検索します。
類似度の指標にはユークリッド距離やコサイン類似度がよく使われます。

### ドキュメント抽出：
類似度の高いドキュメントを高い順にK個を選び出します。

### 生成モデルへ入力：
抽出したドキュメントと元のクエリを、LLMに入力します。

最も単純な形は、取得されたドキュメントをプロンプトに組み込む方法です。

```
（プロンプトの例）
引用情報をもとにユーザーの質問に回答してください。

ユーザーの質問: {question}

引用情報: {content}
```

### 回答生成：
生成AIが入力された情報に基づいて、回答を生成します。


## RAGの検索手法

### 全文検索
クエリに含まれる単語やフレーズを直接データベース内のドキュメントと一致させる方法です。一般的には、クエリとドキュメントの中で同じ単語が出現するかを基に関連性を判断します。
いわゆるキーワード検索

### ベクトル検索
クエリとドキュメントをベクトル形式に変換し、これらのベクトル間の類似度（例えばコサイン類似度）を計算して関連するドキュメントを検索する方法です。これにより、文の意味を捉えた検索が可能になります。

### ナレッジグラフ
ナレッジグラフは、実体（エンティティ）とそれらの関係を図形式で表現したデータベースです。情報の検索や質問応答において、関連する実体や関係を効率的に探索するために使用されます。

## ハイブリッド検索
「ベクトル検索+キーワード検索」や「ベクトル検索+ナレッジグラフ」のように、複数の手法を並行して行い、それらの結果を組み合わせてLLMのプロンプトに入れます。それぞれの方法の利点を活かし、より精度の高い検索結果を得ることができます。

## リランキング
ハイブリッド検索のように複数の検索で得た文書に対して、再度ランク付けを行い、関連性が高い文書のみを利用します
![Screenshot_2023-07-12_at_2 49 33_PM](https://github.com/user-attachments/assets/974694ef-a952-4c73-9136-547ea4abcd9b)

## Hyde（Hypothtical Document Embeddings）
「クエリ」を検索に適した形に変換するクエリ変換と呼ばれる手法の一つです。クエリをいったん生成AIに尋ねて、そこで得られた回答を使って、その回答をEmbeddingしてドキュメントを検索する方法です。

## サブクエリ
力クエリをそのままベクトル化して検索に利用するのではなく、入力クエリをサブクエリに分解し、それぞれのサブクエリでのレスポンスを最後に合成して回答するという手法です。

## RAG Fusion
力クエリに類似したクエリをいくつか生成し、それぞれのクエリの検索結果を統合した上で、上位に来るチャンクを回答に利用するという方法です。
入力クエリだけでなく、類似したクエリをLLMに複数生成させて検索する事で、関連性の高い箇所を幅広く取得する事が期待できます。

## チャンク拡張
検索でヒットしたチャンクの前後のチャンクもコンテキストに含めてLLMに渡すという方法になります。
